{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('stackexchange_full_data_tokenized.csv.gz',\n",
    "                  compression='gzip').sample(frac = 1, random_state = 42).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(787845, 7)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   post_id  parent_id  comment_id  \\\n",
      "0    53177        NaN         NaN   \n",
      "1   106024   106023.0         NaN   \n",
      "2   201671        NaN    382490.0   \n",
      "3   388571        NaN    729725.0   \n",
      "4   329114        NaN    623416.0   \n",
      "\n",
      "                                                text category  \\\n",
      "0  What do I do when the normal approximation is ...     post   \n",
      "1  Since every event corresponds to two variables...     post   \n",
      "2  indeed! It looks like a contradiction! is the ...  comment   \n",
      "3  If the analytical study is only for those with...  comment   \n",
      "4  Your dataset size seems okay for such a small ...  comment   \n",
      "\n",
      "                                              tokens  n_tokens  \n",
      "0  what do i do when the normal approximation is ...        52  \n",
      "1  since every event corresponds to two variables...       132  \n",
      "2  indeed ! it looks like a contradiction ! is th...        28  \n",
      "3  if the analytical study is only for those with...        59  \n",
      "4  your dataset size seems okay for such a small ...        34  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the tokens column as list \n",
    "data['tokens'] = data.tokens.apply(lambda token: token.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['yes', ',', 'i', 'think', 'that', 'would', 'be', 'a', 'very', 'interesting', 'and', 'publishable', 'simulation', 'study.', 'since', 'the', 'present', 'formula', 'is', 'based', 'on', 'kurtosis-correction', 'of', 'the', 'variance', 'of', 'the', 'sample', 'variance', ',', 'i', 'would', 'expect', 'that', 'the', 'present', 'result', 'would', 'work', 'best', 'when', 'you', 'have', 'an', 'underlying', 'distribution', 'with', 'a', 'kurtosis', 'parameter', 'that', 'is', 'far', 'from', 'mesokurtic', 'i.e.', ',', 'when', 'the', 'kurtosis-correction', 'matters', 'most', '.', 'since', 'the', 'kurtosis', 'would', 'need', 'to', 'be', 'estimated', 'from', 'the', 'sample', ',', 'it', 'is', 'an', 'open', 'question', 'as', 'to', 'when', 'there', 'would', 'be', 'a', 'substantial', 'improvement', 'in', 'overall', 'performance', '.']),\n",
       "       list(['just', 'came', 'across', 'and', 'i', 'was', 'wondering', 'whether', 'by', 'having', 'all', 'my', 'censored', 'cases', 'at', 'days', 'would', 'violate', 'the', 'censoring', 'independence', 'assumption.', 'additionally', ',', 'i', 'have', 'approximately', 'of', 'the', 'patients', 'that', 'survived.', 'does', 'this', 'violate', 'any', 'assumptions', '?', 'i.e.', 'high', 'censoring']),\n",
       "       list(['thanks.', 'this', 'is', 'a', 'great', 'answer', 'and', 'makes', 'perfect', 'sense.', 'in', 'my', 'application', ',', 'the', 'assumption', 'that', ',', 'then', 'you', \"'re\", 'fine.', 'this', 'is', 'a', 'reasonable', 'assumption', 'in', 'my', 'case.', 'what', 'do', 'you', 'think', '?', 'btw', ',', 'would', 'you', 'happen', 'to', 'have', 'any', 'references', 'that', 'mention', 'this', 'problem', '?', 'i', \"'m\", 'not', 'familiar', 'with', 'econometrics', 'literature', '.']),\n",
       "       list(['can', 'smote', 'deal', 'with', 'categorical', 'variables'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(4).tokens.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train and test regimen\n",
    "train_data = data[data.category.isin(['post', 'comment'])].copy()\n",
    "test_data = data[data.category.isin(['title'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   post_id  parent_id  comment_id  \\\n",
      "0    53177        NaN         NaN   \n",
      "1   106024   106023.0         NaN   \n",
      "2   201671        NaN    382490.0   \n",
      "3   388571        NaN    729725.0   \n",
      "4   329114        NaN    623416.0   \n",
      "\n",
      "                                                text category  \\\n",
      "0  What do I do when the normal approximation is ...     post   \n",
      "1  Since every event corresponds to two variables...     post   \n",
      "2  indeed! It looks like a contradiction! is the ...  comment   \n",
      "3  If the analytical study is only for those with...  comment   \n",
      "4  Your dataset size seems okay for such a small ...  comment   \n",
      "\n",
      "                                              tokens  n_tokens  \n",
      "0  [what, do, i, do, when, the, normal, approxima...        52  \n",
      "1  [since, every, event, corresponds, to, two, va...       132  \n",
      "2  [indeed, !, it, looks, like, a, contradiction,...        28  \n",
      "3  [if, the, analytical, study, is, only, for, th...        59  \n",
      "4  [your, dataset, size, seems, okay, for, such, ...        34  \n"
     ]
    }
   ],
   "source": [
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    post_id  parent_id  comment_id  \\\n",
      "12   391568        NaN         NaN   \n",
      "18    56803        NaN         NaN   \n",
      "29   371726        NaN         NaN   \n",
      "40   177487        NaN         NaN   \n",
      "43   240397        NaN         NaN   \n",
      "\n",
      "                                                 text category  \\\n",
      "12  Is Cov X,Y Z .x always positive? with X,Y,Z, n...    title   \n",
      "18  Can I do a correlation between a likert scale ...    title   \n",
      "29  Representativeness of population by a sample p...    title   \n",
      "40   Setting one feature more influential than others    title   \n",
      "43        Restricted OLS have less variance than OLS?    title   \n",
      "\n",
      "                                               tokens  n_tokens  \n",
      "12  [is, cov, x, ,, y, z, .x, always, positive, ?,...        22  \n",
      "18  [can, i, do, a, correlation, between, a, liker...        19  \n",
      "29  [representativeness, of, population, by, a, sa...         7  \n",
      "40  [setting, one, feature, more, influential, tha...         7  \n",
      "43  [restricted, ols, have, less, variance, than, ...         8  \n"
     ]
    }
   ],
   "source": [
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a ngrams count dict and tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 705309/705309 [01:45<00:00, 6655.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "counts = defaultdict(Counter)\n",
    "\n",
    "for tokens in tqdm(train_data.tokens.values):\n",
    "    for ngram in ngrams(tokens, n = trigrams, \n",
    "                        pad_right = True, pad_left = True,\n",
    "                       left_pad_symbol='<s>', right_pad_symbol='</s>'):\n",
    "        prefix = ngram[:trigrams-1]\n",
    "        token = ngram[trigrams-1]\n",
    "        counts[prefix][token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4243068"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bigrams count\n",
    "len(counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('curvature', 'seems'): \n",
      "Counter({'evident.': 1})\n",
      "('a', 'individually'): \n",
      "Counter({',': 1})\n",
      "('received', 'vague'): \n",
      "Counter({'and': 2})\n",
      "('or', \"'normalicity\"): \n",
      "Counter({\"'\": 1})\n",
      "('least', 'equivalent'): \n",
      "Counter({'.': 1})\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for key in range(5):\n",
    "    prefix = random.choice(list(counts.keys()))\n",
    "    print('{}: \\n{}'.format(prefix, counts[prefix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token count for each bigram\n",
    "\n",
    "tokens_count = [len(value) for key, value in counts.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "plt.hist(tokens_count, bins = 25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2881006\n"
     ]
    }
   ],
   "source": [
    "# bigram with one token\n",
    "bigram_with_one_token = [key for key, value in counts.items() if len(value) == 1]\n",
    "print(len(bigram_with_one_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535241\n"
     ]
    }
   ],
   "source": [
    "# bigram with two tokens\n",
    "bigram_with_two_tokens = [key for key, value in counts.items() if len(value) == 2]\n",
    "print(len(bigram_with_two_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prefix-token probabilites\n",
    "For each prefix-token count, we can divide the count by the total number of the prefix occurence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_freq = defaultdict(dict)\n",
    "\n",
    "for prefix, tokens in counts.items():\n",
    "    prefix_total = sum(counts[prefix].values())\n",
    "    for token, count in tokens.items():\n",
    "        prefix_freq[prefix][token] = count / prefix_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('i', 'bit'): {'the': 0.3333333333333333, 'off': 0.3333333333333333, 'more': 0.3333333333333333}\n",
      "('arabic', 'language.'): {'the': 1.0}\n",
      "('colour', 'mapped'): {'to': 1.0}\n",
      "('most', 'significance'): {'in': 0.14285714285714285, 'tests': 0.5714285714285714, '?': 0.2857142857142857}\n"
     ]
    }
   ],
   "source": [
    "for item in range(4):\n",
    "    prefix = random.choice(list(prefix_freq.keys()))\n",
    "    print(\"{}: {}\".format(prefix, prefix_freq[prefix]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(text, n_words = 50):\n",
    "    for item in range(n_words):\n",
    "        prefix = tuple(text.split()[-trigrams + 1:])\n",
    "        \n",
    "        if len(prefix_freq[prefix]) == 0:\n",
    "            break\n",
    "            \n",
    "        candidates = list(prefix_freq[prefix].keys())\n",
    "        probas = list(prefix_freq[prefix].values())\n",
    "        text += ' ' + np.random.choice(candidates, p =probas)\n",
    "        \n",
    "        if text.endswith('</s>'):\n",
    "            break\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can any bigrams as long as it is in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "the model , does not follow a zipf distribution . </s>\n",
      "********************\n"
     ]
    }
   ],
   "source": [
    "text = 'the model'\n",
    "print('*' * 20)\n",
    "print(generate(text))\n",
    "print('*' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "that distribution in the output shows all pairs of genes to have persuasive force ? </s>\n",
      "********************\n"
     ]
    }
   ],
   "source": [
    "text = 'that distribution'\n",
    "print('*' * 20)\n",
    "print(generate(text))\n",
    "print('*' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "to determine if a and c are mutually exclusive. you can see two ways to take a look at alternative measures of the linear regression with y having the right ballpark for the particular samples tend to get it now. i just could n't i be able justify its use here. neither\n",
      "********************\n"
     ]
    }
   ],
   "source": [
    "text = 'to determine'\n",
    "print('*' * 20)\n",
    "print(generate(text))\n",
    "print('*' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_temperature(text, temperature = 1, n_words = 50):\n",
    "    \n",
    "    for item in range(n_words):\n",
    "        prefix = tuple(text.split()[-trigrams + 1:])\n",
    "        \n",
    "        if len(prefix_freq[prefix]) == 0:\n",
    "            break\n",
    "            \n",
    "        candidates = list(prefix_freq[prefix].keys())\n",
    "        initial_probas = list(prefix_freq[prefix].values())\n",
    "        \n",
    "        denom = sum([p ** temperature for p in initial_probas])\n",
    "        probas = [p ** temperature / denom for p in initial_probas]\n",
    "        text += ' ' + np.random.choice(candidates, p = probas)\n",
    "        \n",
    "        if text.endswith('</s>'):\n",
    "            break\n",
    "            \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higher the temperature, the less chaotic the generated text will end up be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "the model bad . , sim.xy , c justifying your analysis should take the label ? . fit bayes the most as the decay we want features to begin pinpoint the problem indeed , or egarch in simultaneous use. b. what gpa would help students to identify invaders , lasers and player\n",
      "0.5\n",
      "the model outputs besides simply differencing. it may only consider one of population that gives rise to good and valid only asymptotically for larger vectors , in h and c alternate except at a distance often euclidean . . linacre j. optimizing rating scale but nothing seems too big </s>\n",
      "1\n",
      "the model outcome is therefore that a non-linear svm work better than the average price per square mm are just another question that i saw another chart that describes the p-value is quite an inconsistency between your outcome in favor of setup , if one population is female , male seq i-\n",
      "3\n",
      "the model . </s>\n",
      "10\n",
      "the model is not a good idea to use the same as the number of observations , and the other hand , if you have a dataset with the same as the number of observations , and the other hand , if you have a look at the end of the data\n"
     ]
    }
   ],
   "source": [
    "text = 'the model'\n",
    "\n",
    "for tau in [0.01, 0.5, 1, 3, 10]:\n",
    "    print(tau)\n",
    "    print(generate_temperature(text, temperature=tau))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity\n",
    "Let us measure the quality of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize  import TreebankWordTokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "def perplexity(sentence):\n",
    "    sentence = tokenizer.tokenize(sentence.lower())\n",
    "    N = len(sentence)\n",
    "    logprob = 0\n",
    "    \n",
    "    for ngram in ngrams(sentence, n = trigrams, \n",
    "                        pad_right = True, pad_left = True,\n",
    "                       left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\"):\n",
    "        try:\n",
    "            prefix = ngram[:trigrams - 1]\n",
    "            token = ngram[trigrams - 1]\n",
    "            logprob += np.log(prefix_freq[prefix][token])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return np.exp(-logprob / N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the perplexity on some sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[perplexity 22.38] the difference between the two approaches is discussed here\n"
     ]
    }
   ],
   "source": [
    "sentence = \"the difference between the two approaches is discussed here\"\n",
    "print(\"[perplexity {:.2f}] {}\".format(perplexity(sentence), sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[perplexity 77.39] the model typically has three unknown variables other than binary classifiers\n"
     ]
    }
   ],
   "source": [
    "sentence = \"the model typically has three unknown variables other than binary classifiers\"\n",
    "print(\"[perplexity {:.2f}] {}\".format(perplexity(sentence), sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[perplexity 181.13] that distribution than it is mostly linear algebra multiplication\n"
     ]
    }
   ],
   "source": [
    "sentence = \"that distribution than it is mostly linear algebra multiplication\"\n",
    "print(\"[perplexity {:.2f}] {}\".format(perplexity(sentence), sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out of vocabulary (OOV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity_with_laplace(sentence, delta = 1):\n",
    "    sentence = tokenizer.tokenize(sentence.lower())\n",
    "    N = len(sentence)\n",
    "    logprob = 0\n",
    "    \n",
    "    for ngram in ngrams(sentence, n = trigrams,\n",
    "                       pad_right=True, pad_left=True,\n",
    "                       left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\"):\n",
    "        prefix = ngram[:trigrams - 1]\n",
    "        token = ngram[trigrams - 1]\n",
    "        \n",
    "        if prefix in list(counts.keys()):\n",
    "            total_counts = sum(counts[prefix].values())\n",
    "            if token in counts[prefix].values():\n",
    "                logprob += np.log((counts[prefix][token] + delta) / (total_counts + delta * N))\n",
    "            else:\n",
    "                logprob += np.log((delta) / (total_counts + delta * N))\n",
    "        else:\n",
    "            logprob += -np.log(N)\n",
    "    return np.exp(-logprob / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[perplexity 2064.45] the difference between the two approaches is discussed here\n"
     ]
    }
   ],
   "source": [
    "sentence = \"the difference between the two approaches is discussed here\"\n",
    "print(\"[perplexity {:.2f}] {}\".format(perplexity_with_laplace(sentence, delta = 10), sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[perplexity 183.66] the model typically has three unknown variables other than binary classifiers\n"
     ]
    }
   ],
   "source": [
    "sentence = \"the model typically has three unknown variables other than binary classifiers\"\n",
    "print(\"[perplexity {:.2f}] {}\".format(perplexity_with_laplace(sentence, delta = 10), sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[perplexity 396.74] that distribution than it is mostly linear algebra multiplication\n"
     ]
    }
   ],
   "source": [
    "sentence = \"that distribution than it is mostly linear algebra multiplication\"\n",
    "print(\"[perplexity {:.2f}] {}\".format(perplexity_with_laplace(sentence, delta = 10), sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity on the test corpus and sentence probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculates the probability of a sentence\n",
    "\n",
    "def logproba_of_sentence(sentence, delta = 1):\n",
    "    sentence = tokenizer.tokenize(sentence.lower())\n",
    "    logproba = 0\n",
    "    \n",
    "    for ngram in ngrams(sentence, n = trigrams, \n",
    "                       pad_right=True, pad_left=True,\n",
    "                       left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\"):\n",
    "        prefix = ngram[:trigrams - 1]\n",
    "        token = ngram[trigrams - 1]\n",
    "        try:\n",
    "            logproba += np.log(prefix_freq[prefix][token])\n",
    "        except:\n",
    "            pass\n",
    "    return logproba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculates the perplexity on whole set of sentences\n",
    "\n",
    "def corpus_perplexity(corpus):\n",
    "    corpus_sentences = ' '.join(corpus)\n",
    "    \n",
    "    corpus_tokens = tokenizer.tokenize(corpus_sentences.lower())\n",
    "    N = len(tokens)\n",
    "    \n",
    "    logproba = 0\n",
    "    \n",
    "    for sentence in tqdm(corpus):\n",
    "        logproba += logproba_of_sentence(sentence)\n",
    "        \n",
    "    return np.exp(-logproba / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 8512.90it/s]\n",
      "/home/adelard/anaconda3/envs/allennlp/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perplexity of a 500 sample of titles\n",
    "corpus = test_data.text.sample(1000, random_state=42).values\n",
    "corpus_perplexity(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82536/82536 [00:09<00:00, 8974.19it/s]\n",
      "/home/adelard/anaconda3/envs/allennlp/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perplexity of the whole test corpus\n",
    "corpus_perplexity(test_data.text.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building an n-gram language model with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('stackexchange_full_data_tokenized.csv.gz',\n",
    "                  compression='gzip').sample(frac = 1, random_state = 42).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the tokens column as list \n",
    "data['tokens'] = data.tokens.apply(lambda token: token.split())\n",
    "\n",
    "# creating train and test regimen\n",
    "train_data = data[data.category.isin(['post', 'comment'])].copy()\n",
    "test_data = data[data.category.isin(['title'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>tokens</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What do I do when the normal approximation is ...</td>\n",
       "      <td>post</td>\n",
       "      <td>[what, do, i, do, when, the, normal, approxima...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106024</td>\n",
       "      <td>106023.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Since every event corresponds to two variables...</td>\n",
       "      <td>post</td>\n",
       "      <td>[since, every, event, corresponds, to, two, va...</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>382490.0</td>\n",
       "      <td>indeed! It looks like a contradiction! is the ...</td>\n",
       "      <td>comment</td>\n",
       "      <td>[indeed, !, it, looks, like, a, contradiction,...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>388571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>729725.0</td>\n",
       "      <td>If the analytical study is only for those with...</td>\n",
       "      <td>comment</td>\n",
       "      <td>[if, the, analytical, study, is, only, for, th...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>329114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>623416.0</td>\n",
       "      <td>Your dataset size seems okay for such a small ...</td>\n",
       "      <td>comment</td>\n",
       "      <td>[your, dataset, size, seems, okay, for, such, ...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id  parent_id  comment_id  \\\n",
       "0    53177        NaN         NaN   \n",
       "1   106024   106023.0         NaN   \n",
       "2   201671        NaN    382490.0   \n",
       "3   388571        NaN    729725.0   \n",
       "4   329114        NaN    623416.0   \n",
       "\n",
       "                                                text category  \\\n",
       "0  What do I do when the normal approximation is ...     post   \n",
       "1  Since every event corresponds to two variables...     post   \n",
       "2  indeed! It looks like a contradiction! is the ...  comment   \n",
       "3  If the analytical study is only for those with...  comment   \n",
       "4  Your dataset size seems okay for such a small ...  comment   \n",
       "\n",
       "                                              tokens  n_tokens  \n",
       "0  [what, do, i, do, when, the, normal, approxima...        52  \n",
       "1  [since, every, event, corresponds, to, two, va...       132  \n",
       "2  [indeed, !, it, looks, like, a, contradiction,...        28  \n",
       "3  [if, the, analytical, study, is, only, for, th...        59  \n",
       "4  [your, dataset, size, seems, okay, for, such, ...        34  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE\n",
    "from nltk.lm import Vocabulary\n",
    "\n",
    "padded_train_data = [ngrams(t, n = trigrams, pad_right=True, pad_left=True,\n",
    "          left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\") for t in train_data.tokens.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word for sent in train_data.tokens for word in sent]\n",
    "words.extend([\"<s>\", \"</s>\"])\n",
    "vocab = Vocabulary(words, unk_cutoff=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = MLE(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model.fit(padded_train_data, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import TreebankWordTokenizer\n",
    "from nltk.lm import MLE\n",
    "from nltk.lm.preprocessing import pad_both_ends, padded_everygram_pipeline\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "train_data['tokens'] = train_data.text.apply(lambda token: tokenizer.tokenize(token.lower()))\n",
    "\n",
    "padded_line = [list(pad_both_ends(train_data, n=2))]\n",
    "\n",
    "train, vocab = padded_everygram_pipeline(2, padded_line)\n",
    "\n",
    "lm = MLE(2)\n",
    "lm.fit(train, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NgramCounter with 2 ngram orders and 21 ngrams>\n"
     ]
    }
   ],
   "source": [
    "print(lm.counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:allennlp] *",
   "language": "python",
   "name": "conda-env-allennlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
