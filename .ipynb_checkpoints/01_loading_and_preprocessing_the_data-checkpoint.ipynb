{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading and Preparing the Dataset\n",
    "Language is very domain specific. Businesses collect text-based datasets that are tailored to their domains (legal, healthcare, insurance, social networks, finance, etc.). These domain-specific corpuses can then be exploited in multiple ways: entity recognition, search indexing, query completion, product recommendations systems, or sentiment analysis, to name just a few.\n",
    "\n",
    "Language models are at the core of many natural language processing (NLP) applications like the ones listed in the previous paragraph. Simply put, given surrounding or preceding words, a language model predicts a word. As you will see, you can directly exploit language models for any application that generates text, such as machine translation, speech to text, text generation, or query completion applications.\n",
    "\n",
    "Off-the-shelf models which are trained on large generic corpuses do not reflect the particularities of a given business domain and corpus. For instance, completing the query \"how to avoid over…\" will not give the same results in the general public domain (overeating, overthinking, …) compared to a data science context where “overfitting” would be a more appropriate completion.\n",
    "\n",
    "To reap the benefits of domain-specific corpuses, we must build language models that are tuned to the particular vocabulary of the domain at hand. Since Stack Exchange operates domain specific forums, the content of these forums constitutes perfect corpuses for building domain specific language models.\n",
    "\n",
    "In this Project, we will be building statistics-focused language models using gradually more complex methods. We will evaluate and apply these models to the tasks of:\n",
    "\n",
    "- Query completion\n",
    "- Larger text generation\n",
    "- Sentence selection\n",
    "\n",
    "At the end of this project, you will be able to build the foundations of any domain-specific NLP system by creating the most a robust and efficient language model.\n",
    "\n",
    "Here we will working the Stack Exchange dataset. \n",
    "\n",
    "The link to the dataset is available here:\n",
    "\n",
    "https://alexip-ml.s3.amazonaws.com/stackexchange_812k.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and cleaning the data\n",
    "The goal here is threefold:\n",
    " 1. We want to reduce the noise in the original raw text by removing everything that does not bring information to the language model. Everything that is not exactly text: html tags, math notations, urls, etc.\n",
    " 2. We want to prepare the corpus and make it ready for our language model by tokenizing the text.\n",
    " 3. And finally, we want to remove rows with short or very long texts. As you will see, some of the entries are mostly made of large numerical tables. Entries that are too long will not be good reflection of the corpus. Entries that are too short will not bring relevant information to the language model either. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "\n",
    "import csv\n",
    "import copy\n",
    "import pandas as pd\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data and shuffling it at the same time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_csv('https://alexip-ml.s3.amazonaws.com/stackexchange_812k.csv.gz',\n",
    "                   compression='gzip').sample(frac = 1, random_state = 42).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "812132"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(812132, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a small dataset to help with computation on a single machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = copy.deepcopy(full_data[:80000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>208246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;I am analyzing data (size/survival) of two ...</td>\n",
       "      <td>post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>401059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>750748.0</td>\n",
       "      <td>@Tim Does it mean that I am interpreting the N...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374050.0</td>\n",
       "      <td>Well, looking back on that, it is only true th...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>238691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>453902.0</td>\n",
       "      <td>Have you considered using the post-interventio...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153274</td>\n",
       "      <td>72117.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;Perhaps you're already aware of this, but C...</td>\n",
       "      <td>post</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id  parent_id  comment_id  \\\n",
       "0   208246        NaN         NaN   \n",
       "1   401059        NaN    750748.0   \n",
       "2     2132        NaN    374050.0   \n",
       "3   238691        NaN    453902.0   \n",
       "4   153274    72117.0         NaN   \n",
       "\n",
       "                                                text category  \n",
       "0  <p>I am analyzing data (size/survival) of two ...     post  \n",
       "1  @Tim Does it mean that I am interpreting the N...  comment  \n",
       "2  Well, looking back on that, it is only true th...  comment  \n",
       "3  Have you considered using the post-interventio...  comment  \n",
       "4  <p>Perhaps you're already aware of this, but C...     post  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the types of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment    54421\n",
      "post       16611\n",
      "title       8968\n",
      "Name: category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(small_data.category.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "simulating dependent bernoulli variates\n",
      "*************************\n",
      "Linear regression for feature selection\n",
      "*************************\n",
      "Rearrange regression equation that includes a dummy variable\n",
      "*************************\n",
      "Finding kind of dependency\n"
     ]
    }
   ],
   "source": [
    "# sample titles\n",
    "for title in small_data[small_data.category == 'title'].text.sample(4).values:\n",
    "    print(\"*\" * 25)\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the structure of the posts, we can see that the text have html tags and latex formatted equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "<p>Principal component regression (PCR) in fact is regression on PC scores but not PCs. Why then in so many books and tutorials do they say something like, </p>\n",
      "\n",
      "<blockquote>\n",
      "  <p>in statistics, principal component regression (PCR) is a regression analysis that uses principal component analysis when estimating regression coefficients</p>\n",
      "</blockquote>\n",
      "\n",
      "<p>(<a href=\"http://en.wikipedia.org/wiki/Principal_component_regression\">wiki</a>), and also in the famous book <a href=\"http://rads.stackoverflow.com/amzn/click/1441929991\">Principal Component Analysis</a> (Jolliffe, 2002, page 169) it says</p>\n",
      "\n",
      "<blockquote>\n",
      "  <p>... which [PCR] has simply replaced the predictor variables by their PCs in the regression model</p>\n",
      "</blockquote>\n",
      "\n",
      "<p>It makes me quite confused.</p>\n",
      "\n",
      "*************************\n",
      "<p>The ELBO is, as usual, given by </p>\n",
      "\n",
      "<p><span class=\"math-container\">\\begin{align}\n",
      "\\mathcal{L} ( q ) &amp;= \\log p ( x ) - KL ( q ( z ) || p ( z | x) ) \\\\\n",
      "&amp;= \\int q ( z ) \\log \\frac{ p ( x, z ) }{ q ( z )} dz \\\\\n",
      "&amp;= \\mathbf{E}_q \\left[ \\log p ( x, z ) \\right] + \\mathcal{H} ( q )\n",
      "\\end{align}</span></p>\n",
      "\n",
      "<p>where <span class=\"math-container\">$\\mathcal{H}$</span> is the entropy.</p>\n",
      "\n",
      "<p>Now, if <span class=\"math-container\">$q ( z ) = \\mathcal{N} ( \\mu, \\Sigma )$</span>, one has that <span class=\"math-container\">$ \\mathcal{H} ( q ) = \\frac{1}{2} \\log \\det \\left( 2 \\pi e \\Sigma \\right)$</span>. </p>\n",
      "\n",
      "<p>Moreover, if <span class=\"math-container\">$\\xi \\sim \\mathcal{N} ( 0, I )$</span>, then <span class=\"math-container\">$\\mu + \\Sigma^{1/2} \\xi$</span> is distributed as <span class=\"math-container\">$q$</span>. As a result, one can write </p>\n",
      "\n",
      "<p><span class=\"math-container\">\\begin{align}\n",
      "\\mathbf{E}_q \\left[ \\log p ( x, z ) \\right] = \\mathbf{E}_{\\xi \\sim \\mathcal{N} ( 0, I )} \\left[ \\log p ( x, \\mu + \\Sigma^{1/2} \\xi ) \\right].\n",
      "\\end{align}</span></p>\n",
      "\n",
      "<p>This allows us to write the ELBO as a function of <span class=\"math-container\">$( \\mu, \\Sigma )$</span>:</p>\n",
      "\n",
      "<p><span class=\"math-container\">\\begin{align}\n",
      "\\mathcal{L} ( \\mu, \\Sigma ) &amp;= \\mathbf{E}_{\\xi \\sim \\mathcal{N} ( 0, I )} \\left[ \\log p ( x, \\mu + \\Sigma^{1/2} \\xi ) \\right] + \\frac{1}{2} \\log \\det \\left( 2 \\pi e \\Sigma \\right).\n",
      "\\end{align}</span></p>\n",
      "\n",
      "<p>One can estimate gradients of the first term by noting that</p>\n",
      "\n",
      "<p><span class=\"math-container\">\\begin{align}\n",
      "\\nabla_{ ( \\mu, \\Sigma) } \\mathbf{E}_{\\xi \\sim \\mathcal{N} ( 0, I )} \\left[ \\log p ( x, \\mu + \\Sigma^{1/2} \\xi ) \\right] = \\mathbf{E}_{\\xi \\sim \\mathcal{N} ( 0, I )} \\left[  \\nabla_{ ( \\mu, \\Sigma) } \\log p ( x, \\mu + \\Sigma^{1/2} \\xi ) \\right]\n",
      "\\end{align}</span></p>\n",
      "\n",
      "<p>and thus gradients can be estimated unbiasedly by Monte Carlo. Gradients of the second term can be obtained analytically.</p>\n",
      "\n",
      "<p>In closing, one can compute unbiased estimates of the gradient of <span class=\"math-container\">$\\mathcal{L} ( \\mu, \\Sigma )$</span>, which allows for efficient gradient-based optimisation of the ELBO. This is roughly the idea behind <a href=\"https://arxiv.org/abs/1603.00788\" rel=\"nofollow noreferrer\">Automatic Differentiation Variational Inference</a>.</p>\n",
      "\n",
      "*************************\n",
      "<p>I have survey that asks respondents about the number of barriers they've experienced. The question lists different types of barriers, and respondents are asked to check each one they've experienced (so it's a \"check all that apply\" type question). They have 17 barriers to choose from. For each respondent, I've summed these to get the total number of barriers endorsed (which ranges from 0 - 17, M = 8.7, SD = 3.8). I would like to treat this as my DV in a mixed model. My question is, would it be best to analyze this type of outcome using an ordinal model or a poisson model? Or is this an empirical question I should explore during modeling? </p>\n",
      "\n",
      "*************************\n",
      "<p>I have incomplete regression output subsisting of the sample size, the standard error of the regression coefficient, and the p-value for two variables in a regression model. Can I determine what the regression coefficients are? Can I infer which coefficient indicates a larger value for the regression coefficient?</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for post in small_data[small_data.category == 'post'].text.sample(4).values:\n",
    "    print('*' * 25)\n",
    "    print(post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the structure of the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "Thanks, for your detailed comment. At the interview I proposed to calculate MSE (Mean Squared Error) to estimate differences between human frequencies and machine frequencies. Machine with smaller MSE I suggested to be a more realistic coin flipper. The interviewer said that my idea is \"at least some solution\", yet not a good one, as I concluded from his words. Why Hellinger distance is better the MSE?\n",
      "*************************\n",
      "To give a rough idea, I found using R that sampling 10 million uniform variates and applying the quantile function for a beta distribution (both shape parameters equal to 2) with `qbeta(runif(1e7), 2, 2)` takes about 16 times as long as generating 10 million beta variates with `rbeta(1e7, 2, 2)`. So I'd guess $k$ has to be large enough to remove something like nine-tenths of the beta's probability mass before inverse transform sampling becomes faster.\n",
      "*************************\n",
      "How do you define \"belonging to distribution\"? With non-zero probability anything in $-\\infty$ to $\\infty$ \"belongs\" to normal distribution.\n",
      "*************************\n",
      "But is it always the case that fixed effects have zero variance? Also according to Wikipedia, a fixed effect can has non-random variability. This isn't the same as zero variance...\n"
     ]
    }
   ],
   "source": [
    "# sample of comments\n",
    "\n",
    "for sample in small_data[small_data.category == 'comment'].text.sample(4).values:\n",
    "    print('*' * 25)\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up the raw text\n",
    "Were are going to remove the following characters:\n",
    "- html tags\n",
    "- line returns\n",
    "- URLs\n",
    "- Mathematical expressions in Latex\n",
    "- Integers numbers\n",
    "- @someone characters\n",
    "- digits\n",
    "- Language punctuations\n",
    "- and extra spaces\n",
    "\n",
    "For that we are using a series of simple regular expression patterns and the following pandas dataframe pattern:\n",
    "- $pattern = r\" some regex pattern\"$\n",
    "- $pd.DataFrame.text.apply(lambda t: re.sub(pattern, ' ', t)$\n",
    "\n",
    "Based on the specific domain knowledge and the task at end, it is up to us to decide which elements should be removed or kept. The sequence of transformation can be modified as well. Not also that the regular expression patterns used here are chosen for their simplicity. Feel free to use more precise patterns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove html tags\n",
    "small_data['text'] = small_data.text.apply(lambda p: re.sub(\"<[^>]*>\",' ', p))\n",
    "\n",
    "# remove line returns\n",
    "small_data['text'] = small_data.text.apply(lambda p: re.sub(\"[\\r\\n]+\",' ', p))\n",
    "\n",
    "# remove urls\n",
    "small_data['text'] = small_data.text.apply(lambda p: re.sub(\"http\\S+\",' ', p))\n",
    "\n",
    "# remove mentions: @someone\n",
    "small_data['text'] = small_data.text.apply(lambda p: re.sub(\"@\\S+\",' ', p))\n",
    "\n",
    "# remove latex expressions\n",
    "small_data['text'] = small_data.text.apply(lambda p: re.sub(\"\\$[^>]*\\$\",' ', p))\n",
    "\n",
    "# remove digit integers\n",
    "small_data['text'] = small_data.text.apply(lambda p: re.sub(\"\\d+\",' ', p))\n",
    "\n",
    "# remove some of the punctuation but keep ,.!? and - \n",
    "punctuation = '\"#$%&()*+/:;<=>@[\\\\]^_`{|}~”“'\n",
    "pattern = r\"[{}]\".format(punctuation)\n",
    "small_data['text'] = small_data.text.apply(lambda p: re.sub(pattern,' ', p))\n",
    "\n",
    "# remove multiple spaces\n",
    "small_data['text'] = small_data.text.apply(lambda p: re.sub(\"\\s\\s+\",' ', p))\n",
    "\n",
    "# remove trailling spaces with strip() function\n",
    "small_data['text'] = small_data.text.apply(lambda p: p.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Linear regression with feature representation confusion - relationship of design matrix column space to the feature space?\n",
      "-------------------------\n",
      "Comparisons on nonparametic, unequal variance data\n",
      "-------------------------\n",
      "How do I interpret this fitted vs residuals plot?\n",
      "-------------------------\n",
      "Convergence of the Bootstrap to the true mean\n"
     ]
    }
   ],
   "source": [
    "# titles should not be changed\n",
    "\n",
    "for p in small_data[small_data.category == 'title'].text.sample(4).values:\n",
    "    print('-' * 25)\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "There are many situations where you may train several different classifiers, or use several different feature extraction methods. In the literature authors often give the mean classification error over a set of random splits of the data i.e. after a doubly nested cross-validation , and sometimes give variances on the error over the splits as well. However this on its own is not enough to say that one classifier is significantly better than another. I've seen many different approaches to this - using Chi-squared tests, t-test, ANOVA with post-hoc testing etc. What method should be used to determine statistical significance? Underlying that question is What assumptions should we make about the distribution of classification scores?\n",
      "*************************\n",
      "Imagine, i have a random graph with increase the probability of a third connecting edge in presence of two edges? I would assume one would somehow express this using conditional probabilities, although I can't seem to figure out exactly how.\n",
      "*************************\n",
      "I would suggest a two step approach. The first step would be sampling with replacement - similar to the method used in bootstrapping. In R , you could use newdata sample olddata, replace TRUE You now have a different data set with the same properties as the original. The second step would be to add a random variable centered around zero newdata newdata runif , min - , max Any random variable that is symmetric around zero will work and the bounds of the distribution aren't important. At the end, you should have a completely different set of data with the same properties as the old data set.\n",
      "*************************\n",
      "Basically, I'm trying to use one waveform above to predict another waveform . And Here are my model structure model Sequential model.add LSTM NUM NEURONS, input shape train X.shape , train X.shape , return sequences True model.add LSTM NUM NEURONS, input shape train X.shape , train X.shape model.add Dense NUM OUTPUTS adam optimizers.adam lr LR, beta . , beta . , epsilon None, decay . , amsgrad False model.compile loss 'mse', optimizer adam early stopping EarlyStopping monitor 'val loss', patience PATIENCE model.fit train X, train y, epochs EPOCHES, batch size BATCH SIZE, validation data test X, test y , callbacks early stopping, tbCallBack , verbose , shuffle False The shape of train X and train y is , , , . However, the LSTM cannot provide an accurate prediction Can anyone tell me which part I did wrong?\n"
     ]
    }
   ],
   "source": [
    "# posts should have much less clutter\n",
    "\n",
    "for p in small_data[small_data.category == 'post'].text.sample(4).values:\n",
    "    print('*' * 25)\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "That is one very well written question!\n",
      "*************************\n",
      "You're welcome, If you want a classifier to say 'yes' unless the case for 'no' is really strong, it means you are prioritizing sensitivity over specificity, from a ml ROC-esque perspective. I don't have a problem with saying that that activity is analogous to hypothesis testing, although they many not look quite the same on the surface. The thing about a logical structure is that instances can occur in any number of contexts, even where things look very different.\n",
      "*************************\n",
      "Related thread Best practice when analysing pre-post treatment-control designs and probably also of interest Which t-test to use for a two-group pre- post-test design?\n",
      "*************************\n",
      "That's the entire crux of the question. I have to pass sequences in in chunks as that's how the underlying language model is trained. However the point is that all of the chunks are related so we want to calculate error on the final point and backpropagate and update weights accordingly.\n"
     ]
    }
   ],
   "source": [
    "# comments should also be less noisy\n",
    "\n",
    "for p in small_data[small_data.category == 'comment'].text.sample(4).values:\n",
    "    print('*' * 25)\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "Tokenization is the task of splitting a text into meaningful segments, called tokens. The input to the tokenizer is a unicde text, and the output is a container for accessing linguistic annotations for Doc. There many librairies to choose from. Here we use the Tokenization from spacy librairy. spaCy's tokenization is non-destructive, which means that you will always be able to reconstruct the original input from tokenized output. Whitespace information is preserved in the tokens and no information is added or removed during tokenization. This is kind of a core principle of spaCy's Doc object: \n",
    "- doc.text == input_text\n",
    "\n",
    "should always hold true. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "small_data['tokens'] = small_data.text.apply(lambda token: tokenizer.tokenize(token.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many count of tokens do we have in each text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data['n_tokens'] = small_data.tokens.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    80000.000000\n",
       "mean        56.755738\n",
       "std         98.315008\n",
       "min          0.000000\n",
       "25%         15.000000\n",
       "50%         33.000000\n",
       "75%         66.000000\n",
       "max       7994.000000\n",
       "Name: n_tokens, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_data.n_tokens.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4f49782850>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "small_data.n_tokens.hist(bins = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check some of the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I use a GLM to find the best fit for my included explanatory variables. I'm asked to estimate the effect size for this GLM and I can't find exactly what's about. I founnd this R code Recent version of R used . library 'pwr' library 'lmSupport' modelEffectSizes model modelPower u , v , alpha . , peta . How can I apply this for my dataset? In particular, I am unclear on what peta and u stand for. I suppose v refers to the sample size. Here is my dataset res structure list Motif structure c L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L , .Label c Home , Other , class factor , Type structure c L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L , .Label c Irregular , Regular , class factor , Times c L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L , Genre structure c L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L , .Label c Female , Male , class factor , Age c L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L , No c L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L , Yes c L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L , .Names c Motif , Type , Times , Genre , Age , No , Yes , row.names c NA, - L , class data.frame attach res model glm Yes Genre Times Type Age, family binomial summary model Edit Trial with effects package library 'effects' attach res mod.result lt - glm Yes Genre Times Type Age, family binomial eff.result lt - allEffects mod.result model Yes Genre Times Type Age Genre effect Genre Female Male . . Times effect Times . . . . . Type effect Type Irregular Regular . . Age effect Age . . . . . Is this the correct way to calculate effect size? Effects seems very low while I get a significant p-value for Genre and Times . Why is that? EDIT This is my last trial before losing hope on this library lmSupport attach res binom.mod glm Yes Genre Times Type Age, family binomial anova binom.mod modelEffectSizes binom.mod modelPower pc , pa , N , alpha . , peta . Results from Power Analysis pEta . pa pc alpha . N . What I understood is that I should take the lowest peta value from the ANOVA, that pc represent the number of predictors and pa the number of predictors together with the effect of interest. source\n"
     ]
    }
   ],
   "source": [
    "# this one has a very long series of \"L\"\n",
    "print(small_data[small_data.n_tokens > 5000].text.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most of the longest texts are composed of tables with limited semantic values. Let's remove rows that have more than an arbirtrary number of tokens (let's say 5000) as well rows that have too few tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77634, 7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_data = small_data[(small_data.n_tokens > 4) & (small_data.n_tokens < 5000)].reset_index(drop=True)\n",
    "small_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment    53115\n",
       "post       16434\n",
       "title       8085\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_data.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data\n",
    "We could export the dataframe as such using a pickle file format.\n",
    "But, if we want to keep the original csv format it is going to be easier, if we transform the list of tokens into a space separated string. On retrieval we will only have to split the string to get back the list of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i am analyzing data size survival of two group...\n",
       "1    does it mean that i am interpreting the nfl th...\n",
       "2    well , looking back on that , it is only true ...\n",
       "3    have you considered using the post-interventio...\n",
       "4    perhaps you 're already aware of this , but ch...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_data['tokens'] = small_data.tokens.apply(lambda token: ' '.join(token))\n",
    "small_data.tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let us export the dataframe into a csv file. We will use that csv file as the new cleaned up and filtered out dataset to build our language model in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data.to_csv('stackexchange_small_data_tokenized.csv', quoting = csv.QUOTE_ALL, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe as gzip file, we use compression=\"gzip\" in\n",
    "# addition to the filename argument to to_csv() function.\n",
    "small_data.to_csv('stackexchange_small_data_tokenized.csv.gz',\n",
    "                  index = False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Adding or removing steps to this first text processing taks will us to test different approaches in our language model building process. For example, we can decide not to remove the latex formatted mathematical expression and see if the language model is able to create grammatically valid equations. We could also implement a step to handle contractions (don't, let's, ...) and see if that improves the quality of the generated text. Finally, we could also decide to work on the vocabulary and filter out types or non-english unknown words using named entity recognition to tag specific tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:allennlp] *",
   "language": "python",
   "name": "conda-env-allennlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
