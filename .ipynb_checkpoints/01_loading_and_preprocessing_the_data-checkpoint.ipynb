{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading and Preparing the Dataset\n",
    "Language is very domain specific. Businesses collect text-based datasets that are tailored to their domains (legal, healthcare, insurance, social networks, finance, etc.). These domain-specific corpuses can then be exploited in multiple ways: entity recognition, search indexing, query completion, product recommendations systems, or sentiment analysis, to name just a few.\n",
    "\n",
    "Language models are at the core of many natural language processing (NLP) applications like the ones listed in the previous paragraph. Simply put, given surrounding or preceding words, a language model predicts a word. As you will see, you can directly exploit language models for any application that generates text, such as machine translation, speech to text, text generation, or query completion applications.\n",
    "\n",
    "Off-the-shelf models which are trained on large generic corpuses do not reflect the particularities of a given business domain and corpus. For instance, completing the query \"how to avoid over…\" will not give the same results in the general public domain (overeating, overthinking, …) compared to a data science context where “overfitting” would be a more appropriate completion.\n",
    "\n",
    "To reap the benefits of domain-specific corpuses, we must build language models that are tuned to the particular vocabulary of the domain at hand. Since Stack Exchange operates domain specific forums, the content of these forums constitutes perfect corpuses for building domain specific language models.\n",
    "\n",
    "In this Project, we will be building statistics-focused language models using gradually more complex methods. We will evaluate and apply these models to the tasks of:\n",
    "\n",
    "- Query completion\n",
    "- Larger text generation\n",
    "- Sentence selection\n",
    "\n",
    "At the end of this project, you will be able to build the foundations of any domain-specific NLP system by creating the most a robust and efficient language model.\n",
    "\n",
    "Here we will working the Stack Exchange dataset. \n",
    "\n",
    "The link to the dataset is available here:\n",
    "\n",
    "https://alexip-ml.s3.amazonaws.com/stackexchange_812k.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and cleaning the data\n",
    "The goal here is threefold:\n",
    " 1. We want to reduce the noise in the original raw text by removing everything that does not bring information to the language model. Everything that is not exactly text: html tags, math notations, urls, etc.\n",
    " 2. We want to prepare the corpus and make it ready for our language model by tokenizing the text.\n",
    " 3. And finally, we want to remove rows with short or very long texts. As you will see, some of the entries are mostly made of large numerical tables. Entries that are too long will not be good reflection of the corpus. Entries that are too short will not bring relevant information to the language model either. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "\n",
    "import csv\n",
    "import copy\n",
    "import pandas as pd\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data and shuffling it at the same time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_csv('https://alexip-ml.s3.amazonaws.com/stackexchange_812k.csv.gz',\n",
    "                   compression='gzip').sample(frac = 1, random_state = 42).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "812132"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(812132, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a small dataset to help with computation on a single machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small_data = copy.deepcopy(full_data[:80000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>208246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;I am analyzing data (size/survival) of two ...</td>\n",
       "      <td>post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>401059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>750748.0</td>\n",
       "      <td>@Tim Does it mean that I am interpreting the N...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374050.0</td>\n",
       "      <td>Well, looking back on that, it is only true th...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>238691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>453902.0</td>\n",
       "      <td>Have you considered using the post-interventio...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153274</td>\n",
       "      <td>72117.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;Perhaps you're already aware of this, but C...</td>\n",
       "      <td>post</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id  parent_id  comment_id  \\\n",
       "0   208246        NaN         NaN   \n",
       "1   401059        NaN    750748.0   \n",
       "2     2132        NaN    374050.0   \n",
       "3   238691        NaN    453902.0   \n",
       "4   153274    72117.0         NaN   \n",
       "\n",
       "                                                text category  \n",
       "0  <p>I am analyzing data (size/survival) of two ...     post  \n",
       "1  @Tim Does it mean that I am interpreting the N...  comment  \n",
       "2  Well, looking back on that, it is only true th...  comment  \n",
       "3  Have you considered using the post-interventio...  comment  \n",
       "4  <p>Perhaps you're already aware of this, but C...     post  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the types of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment    553076\n",
      "post       167304\n",
      "title       91752\n",
      "Name: category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(full_data.category.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "Practical meaning of expected value, standard deviation & correlation\n",
      "*************************\n",
      "How can the Cross-correlation of two time series be used to measure similarity between vectors\n",
      "*************************\n",
      "Longitudinal design - repeated measures, non-parametric, non-balanced design\n",
      "*************************\n",
      "Visualizing multi-dimensional data (LSI) in 2D\n"
     ]
    }
   ],
   "source": [
    "# sample titles\n",
    "for title in full_data[full_data.category == 'title'].text.sample(4).values:\n",
    "    print(\"*\" * 25)\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the structure of the posts, we can see that the text have html tags and latex formatted equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "<p><a href=\"http://williamlowe.net/software/jfreq/\" rel=\"nofollow\">JFreq</a> might do what you want.  There's a command line version too.  </p>\n",
      "\n",
      "*************************\n",
      "<p>Multiple articles claim that AdaGrad does not work well when the square-root in the formula is not taken. <a href=\"http://cs231n.github.io/neural-networks-3/#ada\" rel=\"nofollow noreferrer\">This</a> is one such example.</p>\n",
      "\n",
      "<p>$\\theta_{t+1,i} = \\theta_{t,i}-\\dfrac{\\eta}{\\sqrt{G_{t,ii}+\\epsilon}}\\times g_{t,i}$.</p>\n",
      "\n",
      "<p>Here $G_{t,ii}$ represents the summation of previous gradients.\n",
      "Why is it so that the square root is so important?\n",
      "If the reason is related to the fact that $G_{t,ii}$ will become very large and hence will prohibit learning, is it not possible to get the same effect using another hyperparameter $\\beta$ and using $\\beta\\times G_{t,ii}$?</p>\n",
      "\n",
      "<p>Or will a linear scaling down not have the same effect as a non-linear scaling down?</p>\n",
      "\n",
      "*************************\n",
      "<p>If you were to do that then you would be effectively just finding the MLE in a single problem where the distributional family you are using is the union of the family of normal distributions and the family of beta distributions.  That is somewhat strange, since the class of distributions you form include two different parametric forms.  Nevertheless, it is perfectly valid, insofar as what you obtain is still an MLE.  Letting <span class=\"math-container\">$\\mathscr{N}$</span> denote the class of all normal distributions and <span class=\"math-container\">$\\mathscr{B}$</span> denote the class of all beta distributions, your MLE would be:</p>\n",
      "\n",
      "<p><span class=\"math-container\">$$\\hat{F} = \\underset{F \\in \\mathscr{F}}{\\text{arg max }} L_\\mathbf{x}(F)\n",
      "\\quad \\quad \\quad \\mathscr{F} = \\mathscr{N} \\cup \\mathscr{B}.$$</span></p>\n",
      "\n",
      "<p>Taking <span class=\"math-container\">$\\hat{L}_N \\equiv \\underset{F \\in \\mathscr{N}}{\\text{max }} L_\\mathbf{x}(F)$</span> and <span class=\"math-container\">$\\hat{L}_B \\equiv \\underset{F \\in \\mathscr{B}}{\\text{max }} L_\\mathbf{x}(F)$</span> gives you:</p>\n",
      "\n",
      "<p><span class=\"math-container\">$$L_\\mathbf{x}(\\hat{F}) = \\underset{F \\in \\mathscr{F}}{\\text{max }} L_\\mathbf{x}(F) = \\max (\\hat{L}_N, \\hat{L}_B).$$</span></p>\n",
      "\n",
      "<p>Now, it is important to bear in mind that, although this is a valid MLE, you will need to establish whether or not the standard properties of the MLE hold in this case.  Some standard properties of the MLE given in theorems pertaining to parametric models will hold and some will not.  This depends on the required assumptions for these properties, which is complicated in this case.  In determining whether a particular property applies, you will need to examine the proofs of these properties and the required assumptions, and you should bear in mind that in this case you no longer have a class of distributions where there is a smooth \"path\" between all distributions in the class (in a topological sense).<span class=\"math-container\">$^\\dagger$</span>  </p>\n",
      "\n",
      "<p>You can certainly use this MLE as an estimator of the true distribution across a class composed of two distributional families.  Whether this estimator has the desirable statistical properties that hold in simpler cases is a tricky question, and would require a detailed investigation of derivation of those properties in this case.</p>\n",
      "\n",
      "<hr>\n",
      "\n",
      "<p><span class=\"math-container\">$^\\dagger$</span> Actually, this part is a little tricky.  It is made more complicated by the fact that the beta distribution is asymptotically normal for a broad class of limiting cases, so there is arguably a smooth path between all distributions in the class, through the asymptotic limits.  Whether this is sufficient to obtain the required properties for proofs of standard properties of the MLE is something that would require investigation.</p>\n",
      "\n",
      "*************************\n",
      "<p>This is an interesting data set to try to represent graphically, partly because it's not really categorical. Both 3-level factors are ordinal and there is possible interplay between them (presumably, it's harder for a <code>mild</code> <code>baseline</code> to have <code>substantial</code> <code>improvement</code> -- or maybe <code>substantial</code> <code>improvement</code> means something different for each <code>baseline</code>).</p>\n",
      "\n",
      "<p>With multiple variables, there isn't usually a single view that shows all the features you might care about. Some factors will be easier to compare than others. I think your original view is good and would be better with Nick Cox's suggestions: removing duplicate legends and using an ordinal color scale.</p>\n",
      "\n",
      "<p>If you're most interesting in seeing the difference between treatments, you can emphasize the change by using a stacked area plot instead of stacked bars.</p>\n",
      "\n",
      "<p><img src=\"https://i.stack.imgur.com/DJbQJ.png\" alt=\"enter image description here\"></p>\n",
      "\n",
      "<p>I'm usually wary of stacking in general because it's harder to read the middle values, but it does re-enforce the fixed-sum nature of this data. And it makes it easy to read the sum <code>moderate</code>+<code>substantial</code> if that's relevant. I've flipped the order of the <code>improvement</code> levels so that higher is better for the frequency.</p>\n",
      "\n",
      "<p>Without stacking, the equivalent is a slope graph.</p>\n",
      "\n",
      "<p><img src=\"https://i.stack.imgur.com/5m8hj.png\" alt=\"enter image description here\"></p>\n",
      "\n",
      "<p>It's easier to read each level, but harder to understand the interplay. You have to keep in mind that the third line is directly dependent on the other two.</p>\n",
      "\n",
      "<p>Given the ordinal nature of the data, it may be helpful to convert the <code>improvement</code> value into a numeric score, as is often done with <a href=\"http://en.wikipedia.org/wiki/Likert_scale\" rel=\"noreferrer\">Likert</a> data. For instance, <code>none=0</code>, <code>moderate=1</code>, <code>substantial=2</code>. Then you can graph that variable on a continuous scale. The downside is that you have to find a reasonable scoring (e.g., maybe 0, 1 and 5 would be a truer representation).</p>\n",
      "\n",
      "<p><img src=\"https://i.stack.imgur.com/oCmId.png\" alt=\"enter image description here\"></p>\n",
      "\n",
      "<p><em>Colophon</em>: These plots were made with the Graph Builder feature in the software package <a href=\"http://www.jmp.com/\" rel=\"noreferrer\">JMP</a> (which I help develop). Though made interactively, a script, for instance, for the area plot, without the coloring customizations, is:</p>\n",
      "\n",
      "<pre><code>Graph Builder(\n",
      "    Graph Spacing( 15 ),\n",
      "    Variables( X( :treatment ), Y( :frequency ),\n",
      "        Group X( :baseline ), Overlay( :improvement )\n",
      "    ),\n",
      "    Elements( Area( X, Y ) )\n",
      ");\n",
      "</code></pre>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for post in full_data[full_data.category == 'post'].text.sample(4).values:\n",
    "    print('*' * 25)\n",
    "    print(post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the structure of the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "Oh okay. I think I will use dummy variables as you said but only once I get my groups, which is my initial problem.\n",
      "\n",
      "Each set corresponds to a machine. Some machines seem to have the same behaviour regarding their temperature(same y-intercept,same mean...), some don't and I'm hoping to discover something about the resons of those similarity/differences once I form my groups.\n",
      "*************************\n",
      "I know, however that doesn't help me to decide whether using sample entropy or shannon entropy or some other kind of entropy is appropriate for the data that I'm working with.\n",
      "*************************\n",
      "More on this topic and related ones is at http://stats.stackexchange.com/questions/21119/advice-on-scientifically-sound-scale-construction .\n",
      "*************************\n",
      "I don't think he's looking for a perfect fit. He's trying to understand why the extrapolated value is so far off.\n"
     ]
    }
   ],
   "source": [
    "# sample of comments\n",
    "\n",
    "for sample in full_data[full_data.category == 'comment'].text.sample(4).values:\n",
    "    print('*' * 25)\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up the raw text\n",
    "Were are going to remove the following characters:\n",
    "- html tags\n",
    "- line returns\n",
    "- URLs\n",
    "- Mathematical expressions in Latex\n",
    "- Integers numbers\n",
    "- @someone characters\n",
    "- digits\n",
    "- Language punctuations\n",
    "- and extra spaces\n",
    "\n",
    "For that we are using a series of simple regular expression patterns and the following pandas dataframe pattern:\n",
    "- $pattern = r\" some regex pattern\"$\n",
    "- $pd.DataFrame.text.apply(lambda t: re.sub(pattern, ' ', t)$\n",
    "\n",
    "Based on the specific domain knowledge and the task at end, it is up to us to decide which elements should be removed or kept. The sequence of transformation can be modified as well. Not also that the regular expression patterns used here are chosen for their simplicity. Feel free to use more precise patterns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove html tags\n",
    "full_data['text'] = full_data.text.apply(lambda p: re.sub(\"<[^>]*>\",' ', p))\n",
    "\n",
    "# remove line returns\n",
    "full_data['text'] = full_data.text.apply(lambda p: re.sub(\"[\\r\\n]+\",' ', p))\n",
    "\n",
    "# remove urls\n",
    "full_data['text'] = full_data.text.apply(lambda p: re.sub(\"http\\S+\",' ', p))\n",
    "\n",
    "# remove mentions: @someone\n",
    "full_data['text'] = full_data.text.apply(lambda p: re.sub(\"@\\S+\",' ', p))\n",
    "\n",
    "# remove latex expressions\n",
    "full_data['text'] = full_data.text.apply(lambda p: re.sub(\"\\$[^>]*\\$\",' ', p))\n",
    "\n",
    "# remove digit integers\n",
    "full_data['text'] = full_data.text.apply(lambda p: re.sub(\"\\d+\",' ', p))\n",
    "\n",
    "# remove some of the punctuation but keep ,.!? and - \n",
    "punctuation = '\"#$%&()*+/:;<=>@[\\\\]^_`{|}~”“'\n",
    "pattern = r\"[{}]\".format(punctuation)\n",
    "full_data['text'] = full_data.text.apply(lambda p: re.sub(pattern,' ', p))\n",
    "\n",
    "# remove multiple spaces\n",
    "full_data['text'] = full_data.text.apply(lambda p: re.sub(\"\\s\\s+\",' ', p))\n",
    "\n",
    "# remove trailling spaces with strip() function\n",
    "full_data['text'] = full_data.text.apply(lambda p: p.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Writing the likelihood and conditional variance in a ARMAX model or regression with GARCH R rugarch with external covariates\n",
      "-------------------------\n",
      "Smoothing a -by- contingency table\n",
      "-------------------------\n",
      "Convergence of series of dependent random variable, central limit theorem\n",
      "-------------------------\n",
      "Formula for calculating the confidence level of a given confidence interval\n"
     ]
    }
   ],
   "source": [
    "# titles should not be changed\n",
    "\n",
    "for p in full_data[full_data.category == 'title'].text.sample(4).values:\n",
    "    print('-' * 25)\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "i took your monthly values into AUTOBOX , a piece of software that I have helped to develop. It suggested that there was a significant change in parameters at or around period . The final model is here containing both memory and dummy indicators. A level shift is in general an intercept change. The stats are here and here . The Actual cleansed graph is informative while the ACTUAL Fit Forecast is a nice summary with a plot of the model residuals here supporting sufficiency. The plot of the forecasts is here suggesting increasing uncertainty going forward . The ACF,of the residu als is here In summary your approaches were interesting and it appears that between uour course and this you have experienced quite a bit. BY the way the CHOW test for constancy of parameters is here If you look closely at the plot of the original series you can visually detect what AUTOBOX discovered is that there appears to be either a structural change in parameters or a structural change in error variance more visual variability a t a higher level. This linkage between the variance anD the level of the series CAN often be mis-interpreted as justification for a Box-Cox log transformation When and why should you take the log of a distribution of numbers ? .\n",
      "*************************\n",
      "I go to Stat from main menu then Regression - Regression... Although I have selected almost everything I cannot plot the extra info p-value, mean, N, etc above in circle. I use Minitab . . .\n",
      "*************************\n",
      "I am running a regression where my dependent variable is a cross-section of variances. Therefore, I require my predicted values fitted values to be positive. However, when running a simple OLS regression, a small percentage of my fitted values are negative, which is non-intuitive in this case since variance cannot be negative . Please note that approximately, my dependent variable is distributed according to a Chi-square distribution. The output that I need from the regression are the fitted values in the original scale, as well a closed form expression of the MSE Mean Square Error of these fitted values. Is there a way to impose a lower bound on the predicted values?\n",
      "*************************\n",
      "I want to write is itself without real meaning -- just a step in describing the process\n"
     ]
    }
   ],
   "source": [
    "# posts should have much less clutter\n",
    "\n",
    "for p in full_data[full_data.category == 'post'].text.sample(4).values:\n",
    "    print('*' * 25)\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "If the filters all start off the same then they will stay that way. The random initialization means they start off different and from there they learn different things. Look up symmetry breaking in neural networks for more information.\n",
      "*************************\n",
      "The two things that I can think of to represent what the neural net is doing in your case is . Examine the body of predictions that the neural net is getting wrong and present some examples to the user of these tricky cases. . Provide some visual representation of your softmax output. Since this is a binary classifier, you might just represent the output as a probability certainty level. This will allow the user to better understand whether your classifier is relatively confident, or not. Beyond this, describing what the neural network is doing, internally, will likely be very difficult.\n",
      "*************************\n",
      "What Andrew is calling an exponential link is, at least in my experience, more usually called a logarithmic link. Which way you think about it may influence what terminology is congenial, but that does not make such terminology standard.\n",
      "*************************\n",
      "This doesn’t directly address your question, but I just wanted to point out that Bayes’ factors don’t take into account the prior, only the relative likelihood of the hypotheses given the evidence.\n"
     ]
    }
   ],
   "source": [
    "# comments should also be less noisy\n",
    "\n",
    "for p in full_data[full_data.category == 'comment'].text.sample(4).values:\n",
    "    print('*' * 25)\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "Tokenization is the task of splitting a text into meaningful segments, called tokens. The input to the tokenizer is a unicde text, and the output is a container for accessing linguistic annotations for Doc. There many librairies to choose from. Here we use the Tokenization from spacy librairy. spaCy's tokenization is non-destructive, which means that you will always be able to reconstruct the original input from tokenized output. Whitespace information is preserved in the tokens and no information is added or removed during tokenization. This is kind of a core principle of spaCy's Doc object: \n",
    "- doc.text == input_text\n",
    "\n",
    "should always hold true. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "full_data['tokens'] = full_data.text.apply(lambda token: tokenizer.tokenize(token.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many count of tokens do we have in each text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['n_tokens'] = full_data.tokens.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    812132.000000\n",
       "mean         56.595874\n",
       "std          95.182697\n",
       "min           0.000000\n",
       "25%          15.000000\n",
       "50%          33.000000\n",
       "75%          66.000000\n",
       "max       10856.000000\n",
       "Name: n_tokens, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.n_tokens.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "full_data.n_tokens.hist(bins = 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check some of the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I use a GLM to find the best fit for my included explanatory variables. I'm asked to estimate the effect size for this GLM and I can't find exactly what's about. I founnd this R code Recent version of R used . library 'pwr' library 'lmSupport' modelEffectSizes model modelPower u , v , alpha . , peta . How can I apply this for my dataset? In particular, I am unclear on what peta and u stand for. I suppose v refers to the sample size. Here is my dataset res structure list Motif structure c L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L , .Label c Home , Other , class factor , Type structure c L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L , .Label c Irregular , Regular , class factor , Times c L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L , Genre structure c L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L , .Label c Female , Male , class factor , Age c L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L , No c L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L , Yes c L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L , .Names c Motif , Type , Times , Genre , Age , No , Yes , row.names c NA, - L , class data.frame attach res model glm Yes Genre Times Type Age, family binomial summary model Edit Trial with effects package library 'effects' attach res mod.result lt - glm Yes Genre Times Type Age, family binomial eff.result lt - allEffects mod.result model Yes Genre Times Type Age Genre effect Genre Female Male . . Times effect Times . . . . . Type effect Type Irregular Regular . . Age effect Age . . . . . Is this the correct way to calculate effect size? Effects seems very low while I get a significant p-value for Genre and Times . Why is that? EDIT This is my last trial before losing hope on this library lmSupport attach res binom.mod glm Yes Genre Times Type Age, family binomial anova binom.mod modelEffectSizes binom.mod modelPower pc , pa , N , alpha . , peta . Results from Power Analysis pEta . pa pc alpha . N . What I understood is that I should take the lowest peta value from the ANOVA, that pc represent the number of predictors and pa the number of predictors together with the effect of interest. source\n"
     ]
    }
   ],
   "source": [
    "# this one has a very long series of \"L\"\n",
    "print(full_data[full_data.n_tokens > 5000].text.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most of the longest texts are composed of tables with limited semantic values. Let's remove rows that have more than an arbirtrary number of tokens (let's say 5000) as well rows that have too few tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(787845, 7)\n"
     ]
    }
   ],
   "source": [
    "full_data = full_data[(full_data.n_tokens > 4) & (full_data.n_tokens < 5000)].reset_index(drop=True)\n",
    "print(full_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment    539970\n",
       "post       165339\n",
       "title       82536\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data\n",
    "We could export the dataframe as such using a pickle file format.\n",
    "But, if we want to keep the original csv format it is going to be easier, if we transform the list of tokens into a space separated string. On retrieval we will only have to split the string to get back the list of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i am analyzing data size survival of two group...\n",
       "1    does it mean that i am interpreting the nfl th...\n",
       "2    well , looking back on that , it is only true ...\n",
       "3    have you considered using the post-interventio...\n",
       "4    perhaps you 're already aware of this , but ch...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data['tokens'] = full_data.tokens.apply(lambda token: ' '.join(token))\n",
    "full_data.tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let us export the dataframe into a csv file. We will use that csv file as the new cleaned up and filtered out dataset to build our language model in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.to_csv('stackexchange_full_data_tokenized.csv', quoting = csv.QUOTE_ALL, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe as gzip file, we use compression=\"gzip\" in\n",
    "# addition to the filename argument to to_csv() function.\n",
    "full_data.to_csv('stackexchange_full_data_tokenized.csv.gz',\n",
    "                  index = False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Adding or removing steps to this first text processing taks will us to test different approaches in our language model building process. For example, we can decide not to remove the latex formatted mathematical expression and see if the language model is able to create grammatically valid equations. We could also implement a step to handle contractions (don't, let's, ...) and see if that improves the quality of the generated text. Finally, we could also decide to work on the vocabulary and filter out types or non-english unknown words using named entity recognition to tag specific tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:allennlp] *",
   "language": "python",
   "name": "conda-env-allennlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
